kmer2vec model (skipgram).

implementing word2vec algorithm on promotors' sequences 
with sigma70 factor using skip gram model

Hyper-parameters:

embedding_size: 256, window_size: 4

ML Data setup is done



similar_words(TGGAAA)

[('TTGGAA', 0.693156361579895), ('GTGGAA', 0.6880704760551453), ('GGAAAA', 0.6674988269805908), ('ATGGAA', 0.6600114107131958), ('CTGGAA', 0.6420776844024658), ('GGAAAC', 0.6387319564819336), ('GGGAAA', 0.6009426116943359), ('TGGAAC', 0.5963894128799438), ('TGGAAT', 0.5873533487319946), ('TGGAAG', 0.5770734548568726)]




number of cpus: 4
kmer size (vocabulary = unique words): 4089
length of data: 4089

training is done!, and model is saved.
